---
title: "Breaking Mode Collapse: How Verbalized Sampling Restores LLM Creativity"
description: "Ask for a distribution, not a single answer. A training-free method to restore diversity in aligned LLMs."
slug: verbalized-sampling
pubDatetime: 2025-10-03T00:00:00Z
featured: true
draft: false
tags:
  - llm
  - diversity
  - prompting
  - verbalized-sampling
---

import VSPlayground from "@/components/interactives/VSPlayground";
import TypicalityBiasExplainer from "@/components/interactives/TypicalityBiasExplainer";
import TemperatureAblation from "@/components/interactives/TemperatureAblation";
import DiversityGainsVisual from "@/components/evidence/DiversityGainsVisual";
import PostTrainingVisual from "@/components/evidence/PostTrainingVisual";
import USStatesDemo from "@/components/evidence/USStatesDemo";
import ScalingTrendVisualization from "@/components/evidence/ScalingTrendVisualization";
import QuickStart from "@/components/sections/QuickStart";
import QualitativeExamples from "@/components/sections/QualitativeExamples";
import VSVariantsComparison from "@/components/sections/VSVariantsComparison";
import CodeBlock from "@/components/ui/CodeBlock";
import OpeningHook from "@/components/sections/OpeningHook";
import AhaMoment from "@/components/sections/AhaMoment";
import { Sidenote, Figure, Table } from "@/components/academic";

<div className="not-prose flex justify-center gap-3 my-6">
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-green-100 text-green-800 font-semibold">
    ‚ú® Training-Free
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-blue-100 text-blue-800 font-semibold">
    üöÄ Works with GPT, Claude, Gemini
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-purple-100 text-purple-800 font-semibold">
    üìà 1.6-2.1√ó Diversity Gain
  </span>
</div>

## TL;DR

Human readers encounter mode‚Äëcollapsed outputs when asking for multiple ideas. Alignment amplifies typical completions; VS asks for a distribution to recover diversity.

- RLHF introduces **typicality bias** ($\varepsilon>0$) ‚Üí sharpening and mode collapse ($\rho = 1 + \varepsilon/\beta > 1$) [@rafailov2024; @ouyang2022].
- VS prompts for a **probability distribution** over candidates rather than a single instance [@zhang2025vs].
- A threshold $\tau$ allows **diversity tuning** without retraining [@zhang2025vs, pp. 7‚Äì8].

<div className="not-prose mb-10">
  <OpeningHook client:visible />
</div>

## Quick Start

<div className="not-prose mb-12">
  <QuickStart client:load />
</div>

## Why It Works

### 1. Hidden bias in preference data

Human annotators systematically prefer familiar/typical text<Sidenote number={1}>Classic effects include mere exposure and processing fluency [@zajonc1968; @reber2004; @alter2009]. Statistical analyses indicate $\varepsilon>0$ independent of correctness (e.g., paired‚Äëcomparison style tests) [@ouyang2022; @christiano2017].</Sidenote>:

$$r(x,y) = r_{\text{true}}(x,y) + \varepsilon\,\log p_{\text{base}}(y|x).$$

### 2. Sharpening ‚Üí mode collapse

<a id="eq:sharpening" />
$$\pi^*(y|x) \propto \pi_{\text{ref}}(y|x)^{\rho},\quad \rho = 1 + \varepsilon/\beta > 1.$$

When utility is flat across many valid completions, sharpening concentrates mass on typical outputs<Sidenote number={2}>Derivation follows standard KL‚Äëregularized preference learning [@rafailov2024] with typicality‚Äëbiased rewards; see [@zhang2025vs, Eq. 3, p. 4].</Sidenote>.

### 3. Distribution‚Äëlevel recovery (VS)

VS asks for a distribution of candidates with probabilities, recovering pretraining diversity. On the US states task, VS aligns with the corpus distribution ($\mathrm{KL}\approx 0.12$) [@zhang2025vs, p. 3].

<Figure id="us-states" caption="Distribution recovery on US states (VS vs Direct); lower KL indicates closer match to the pretraining distribution [@zhang2025vs, Figure 2].">
  <USStatesDemo client:visible />
</Figure>

<div className="not-prose mb-10">
  <AhaMoment client:visible />
</div>

## Interactive Explainer: Typicality Bias

<div className="not-prose mb-12">
  <TypicalityBiasExplainer client:visible />
</div>

## Try It: Diversity Playground

Adjust the probability threshold œÑ to see how it affects which outputs are included. Lower thresholds = more diversity, higher thresholds = more focused outputs.

<div className="not-prose mb-12">
  <VSPlayground client:visible />
</div>

## Evidence

VS increases diversity by **1.6‚Äì2.1√ó** across poem/story/joke tasks [@zhang2025vs, Figure 3a‚Äìc], improves human preference by **+25.7%** [@zhang2025vs, Table 3], and recovers **66.8%** of base‚Äëmodel diversity after alignment [@zhang2025vs, Figure 4].

<Figure id="diversity-gains" caption="Creative writing diversity improvements with VS (poem, story, joke); VS‚ÄëCoT achieves 1.6‚Äì2.1√ó gains [@zhang2025vs, Figure 3a‚Äìc].">
  <DiversityGainsVisual client:visible />
</Figure>

<Figure id="post-training" caption="Diversity retention across training stages; VS recovers to 66.8% of base diversity [@zhang2025vs, Figure 4].">
  <PostTrainingVisual client:visible />
</Figure>

## VS ‚â† Temperature: Orthogonal Benefits

Temperature changes how you sample from a distribution; VS changes what distribution you request. They combine effectively [@zhang2025vs, Figure 5].

<Figure id="temperature-ablation" caption="VS is orthogonal to temperature; combining the two improves the diversity‚Äìquality frontier [@zhang2025vs, Figure 5].">
  <TemperatureAblation client:visible />
</Figure>

## Larger Models Benefit More

<Figure id="scaling-trend" caption="Larger models benefit ~1.5‚Äì2√ó more from VS [@zhang2025vs, Figure 3e‚Äìf].">
  <ScalingTrendVisualization client:visible />
</Figure>

## VS Matches Fine-Tuned Models

<div className="not-prose bg-gradient-to-r from-purple-50 to-pink-50 rounded-xl p-8 text-center mb-12">
  <h3 className="text-2xl font-bold mb-4">üéØ VS Matches Fine-Tuned Models</h3>
  <p className="text-lg text-gray-700 mb-4">
    In dialogue simulation, GPT-4 with VS matches the performance of a
    <span className="font-semibold"> fine-tuned Llama-3.1-8B model</span>,
    and DeepSeek-R1 with VS even surpasses it.
  </p>
  <p className="text-sm text-gray-600">
    No training required ‚Äî just better prompting [@zhang2025vs, Figure 6a, p. 11].
  </p>
</div>

## VS Variants: When to Use Which

<div className="not-prose mb-12">
  <VSVariantsComparison client:visible />
</div>

Per Appendix H.3, ‚Äúprobability‚Äù performs best for VS‚ÄëStandard/CoT, while ‚Äúconfidence‚Äù is used in VS‚ÄëMulti [@zhang2025vs].

## Qualitative Examples

See the difference in actual outputs between direct prompting and VS:

<div className="not-prose mb-12">
  <QualitativeExamples client:visible />
</div>

## Is VS Right for You?

Use VS when you need creative diversity (stories, jokes, ideas), realistic distributions (simulations, surveys), or variety in synthetic data ‚Äî and when a training‚Äëfree method is preferred. Skip VS for tasks requiring a single correct answer, strict determinism, or maximal speed.

## Implementation Tips

Do:

- Use `k=5` for quality/diversity; larger `k` often degrades quality.
- Ask for ‚Äúprobability‚Äù (not ‚Äúlikelihood‚Äù) in VS‚ÄëStandard/CoT.
- Specify JSON and ensure probabilities sum to 1.
- Use a $\tau$ threshold for diversity control.

Don‚Äôt:

- Use `k>10` unless necessary.
- Mix ‚Äúprobability‚Äù and ‚Äúconfidence‚Äù terms.
- Forget normalization.
- Apply VS to strictly factual/math tasks.

## Frequently Asked Questions

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Does VS hurt accuracy or safety?</summary>
  <p className="mt-3 text-gray-600">
    No. The paper shows VS maintains factual accuracy (Appendix G.7) and safety (Appendix G.8) [@zhang2025vs].
    It only increases diversity for tasks with multiple valid answers.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">What is semantic diversity?</summary>
  <p className="mt-3 text-gray-600">
    Semantic diversity = $1 - \mathrm{mean}(\mathrm{cosine\_similarity})$. It measures how different
    the meanings are across generated responses, not just surface-level word differences.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Why not just use temperature?</summary>
  <p className="mt-3 text-gray-600">
    Temperature and VS are orthogonal. Temperature affects sampling randomness from the same
    distribution, while VS changes the distribution itself [@zhang2025vs, Figure 5]. Combining them gives best results.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-12">
  <summary className="font-semibold cursor-pointer">Which models support VS?</summary>
  <p className="mt-3 text-gray-600">
    Any instruction-following LLM: GPT-4, Claude, Gemini, Llama, Qwen, and even reasoning
    models like o1 and DeepSeek R1. No special access or modifications needed.
  </p>
</details>

## Prompt Recipes

### VS‚ÄëStandard (JSON)

<CodeBlock
  code={`Generate k={5} {TASK} with their probabilities.\nReturn JSON: {\"candidates\":[{\"text\":\"...\",\"prob\":0.28}, ...]}\nOnly include candidates with probability ‚â• {œÑ}. Ensure probabilities sum to 1.`}
  language="text"
  client:idle
/>

### VS‚ÄëCoT

<CodeBlock
  code={`Think step-by-step to enumerate distinct styles/approaches.\nThen generate k={5} {TASK} with probabilities in JSON (probabilities sum to 1).\nOnly include items with probability ‚â• {œÑ}.`}
  language="text"
  client:idle
/>

### VS‚ÄëMulti (confidence)

<CodeBlock
  code={`Generate k={5} {TASK} candidates.\nFor each, return text and confidence ‚àà [0,1]. Only include items with confidence ‚â• {œÑ_conf}.`}
  language="text"
  client:idle
/>

## References

<section id="references" />
