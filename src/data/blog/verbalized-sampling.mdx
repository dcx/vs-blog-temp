---
title: "Breaking Mode Collapse: How Verbalized Sampling Restores LLM Creativity"
description: "Ask for a distribution, not a single answer. A training-free method to restore diversity in aligned LLMs."
slug: verbalized-sampling
pubDatetime: 2025-10-03T00:00:00Z
featured: true
draft: false
tags:
  - llm
  - diversity
  - prompting
  - verbalized-sampling
---

import VSPlayground from "@/components/interactives/VSPlayground";
import TypicalityBiasExplainer from "@/components/interactives/TypicalityBiasExplainer";
import TemperatureAblation from "@/components/interactives/TemperatureAblation";
import DiversityGainsVisual from "@/components/evidence/DiversityGainsVisual";
import PostTrainingVisual from "@/components/evidence/PostTrainingVisual";
import USStatesDemo from "@/components/evidence/USStatesDemo";
import ScalingTrendVisualization from "@/components/evidence/ScalingTrendVisualization";
import QuickStart from "@/components/sections/QuickStart";
import QualitativeExamples from "@/components/sections/QualitativeExamples";
import VSVariantsComparison from "@/components/sections/VSVariantsComparison";
import CodeBlock from "@/components/ui/CodeBlock";

<div className="not-prose flex justify-center gap-3 my-6">
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-green-100 text-green-800 font-semibold">
    ‚ú® Training-Free
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-blue-100 text-blue-800 font-semibold">
    üöÄ Works with GPT, Claude, Gemini
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-purple-100 text-purple-800 font-semibold">
    üìà 1.6-2.1√ó Diversity Gain
  </span>
</div>

## Quick Start

<div className="not-prose mb-12">
  <QuickStart client:load />
</div>

## TL;DR

<div className="not-prose bg-gradient-to-r from-blue-50 to-indigo-50 rounded-xl p-6 mb-12">
  <h3 className="text-2xl font-bold mb-4">TL;DR</h3>
  <ul className="space-y-2">
    <li className="flex items-start gap-2">
      <span className="text-blue-500 mt-1">‚Ä¢</span>
      <span>RLHF creates <strong>typicality bias</strong> (Œµ>0) ‚Üí mode collapse (œÅ=1+Œµ/Œ≤>1)</span>
    </li>
    <li className="flex items-start gap-2">
      <span className="text-blue-500 mt-1">‚Ä¢</span>
      <span>VS recovers diversity by prompting for <strong>probability distributions</strong></span>
    </li>
    <li className="flex items-start gap-2">
      <span className="text-blue-500 mt-1">‚Ä¢</span>
      <span>Threshold œÑ lets you <strong>tune diversity</strong> without retraining</span>
    </li>
  </ul>
</div>

## Why It Works

<div className="not-prose grid grid-cols-1 md:grid-cols-3 gap-6 mb-12">
  <div className="bg-white rounded-lg p-6 shadow-sm border border-gray-200">
    <h3 className="font-semibold text-lg mb-3">1. Hidden Bias</h3>
    <p className="text-gray-600 mb-4">
      Human annotators prefer familiar, typical text (cognitive psychology: mere-exposure effect, processing fluency)
    </p>
    <div className="bg-gray-50 rounded p-3">
      <code className="text-sm">r(x,y) = r_true(x,y) + Œµ¬∑log(p_base)</code>
      <p className="text-xs text-gray-500 mt-2">Œµ>0 confirmed in preference data</p>
    </div>
  </div>

  <div className="bg-white rounded-lg p-6 shadow-sm border border-gray-200">
    <h3 className="font-semibold text-lg mb-3">2. Mathematical Collapse</h3>
    <p className="text-gray-600 mb-4">
      Typicality bias sharpens distributions, causing mode collapse when many answers have equal utility
    </p>
    <div className="bg-gray-50 rounded p-3">
      <code className="text-sm">œÄ*(y|x) ‚àù œÄ_ref(y|x)^œÅ</code>
      <p className="text-xs text-gray-500 mt-2">œÅ = 1 + Œµ/Œ≤ > 1 (sharpening)</p>
    </div>
  </div>

  <div className="bg-white rounded-lg p-6 shadow-sm border border-gray-200">
    <h3 className="font-semibold text-lg mb-3">3. VS Recovery</h3>
    <p className="text-gray-600 mb-4">
      Distribution-level prompts recover pretraining diversity by changing what the "mode" represents
    </p>
    <div className="bg-gray-50 rounded p-3">
      <code className="text-sm">KL(VS || Pretraining) ‚âà 0.12</code>
      <p className="text-xs text-gray-500 mt-2">US states demo (Figure 2)</p>
    </div>
  </div>
</div>

## Interactive Explainer: Typicality Bias

<div className="not-prose mb-12">
  <TypicalityBiasExplainer client:visible />
</div>

## Try It: Diversity Playground

Adjust the probability threshold œÑ to see how it affects which outputs are included. Lower thresholds = more diversity, higher thresholds = more focused outputs.

<div className="not-prose mb-12">
  <VSPlayground client:visible />
</div>

## Evidence

<div className="not-prose grid grid-cols-1 md:grid-cols-3 gap-4 mb-8">
  <div className="bg-white rounded-lg p-6 border-2 border-green-200">
    <div className="text-4xl font-bold text-green-600 mb-2">1.6-2.1√ó</div>
    <div className="font-semibold mb-1">Diversity Gains</div>
    <div className="text-sm text-gray-600">Creative writing tasks</div>
    <div className="text-xs text-gray-500 mt-2">Figure 3a-c, pp. 7-8</div>
  </div>

  <div className="bg-white rounded-lg p-6 border-2 border-blue-200">
    <div className="text-4xl font-bold text-blue-600 mb-2">+25.7%</div>
    <div className="font-semibold mb-1">Human Preference</div>
    <div className="text-sm text-gray-600">Rated higher by humans</div>
    <div className="text-xs text-gray-500 mt-2">Table 3, p. 8</div>
  </div>

  <div className="bg-white rounded-lg p-6 border-2 border-purple-200">
    <div className="text-4xl font-bold text-purple-600 mb-2">66.8%</div>
    <div className="font-semibold mb-1">Diversity Retained</div>
    <div className="text-sm text-gray-600">After alignment</div>
    <div className="text-xs text-gray-500 mt-2">Figure 4, p. 9</div>
  </div>
</div>

### Diversity Gains Across Tasks

<div className="not-prose mb-8">
  <DiversityGainsVisual client:visible />
</div>

### Post-Training Diversity Retention

<div className="not-prose mb-12">
  <PostTrainingVisual client:visible />
</div>

## VS ‚â† Temperature: Orthogonal Benefits

<div className="not-prose bg-amber-50 border-l-4 border-amber-400 p-4 rounded-r-lg mb-6">
  <p className="font-semibold text-amber-900 mb-1">Common Misconception</p>
  <p className="text-amber-800">
    "Can't I just increase temperature?" No! VS and temperature are orthogonal improvements.
    VS changes WHAT is generated (distribution vs instance), while temperature affects HOW it's sampled.
  </p>
</div>

<div className="not-prose mb-12">
  <TemperatureAblation client:visible />
</div>

## Larger Models Benefit More

<div className="not-prose mb-12">
  <ScalingTrendVisualization client:visible />
</div>

## VS Matches Fine-Tuned Models

<div className="not-prose bg-gradient-to-r from-purple-50 to-pink-50 rounded-xl p-8 text-center mb-12">
  <h3 className="text-2xl font-bold mb-4">üéØ VS Matches Fine-Tuned Models</h3>
  <p className="text-lg text-gray-700 mb-4">
    In dialogue simulation, GPT-4 with VS matches the performance of a
    <span className="font-semibold"> fine-tuned Llama-3.1-8B model</span>,
    and DeepSeek-R1 with VS even surpasses it.
  </p>
  <p className="text-sm text-gray-600">
    No training required - just better prompting (Figure 6a, p. 11)
  </p>
</div>

## US States Distribution Recovery

This interactive demo shows how VS recovers the pretraining distribution. The model is asked to name a US state, and we compare the distribution of responses from direct prompting vs. VS.

<div className="not-prose mb-12">
  <USStatesDemo client:visible />
</div>

## VS Variants: When to Use Which

<div className="not-prose mb-12">
  <VSVariantsComparison client:visible />
</div>

## Qualitative Examples

See the difference in actual outputs between direct prompting and VS:

<div className="not-prose mb-12">
  <QualitativeExamples client:visible />
</div>

## Is VS Right for You?

<div className="not-prose bg-white rounded-lg p-6 shadow-sm border border-gray-200 mb-12">
  <div className="space-y-4">
    <div className="flex items-start gap-4">
      <div className="w-8 h-8 bg-green-100 rounded-full flex items-center justify-center flex-shrink-0">
        <span className="text-green-600 font-bold">‚úì</span>
      </div>
      <div>
        <p className="font-semibold">Use VS if you need:</p>
        <ul className="text-sm text-gray-600 mt-1 space-y-1">
          <li>‚Ä¢ Creative diversity (stories, jokes, ideas)</li>
          <li>‚Ä¢ Realistic distributions (simulation, surveys)</li>
          <li>‚Ä¢ Synthetic data variety</li>
          <li>‚Ä¢ Training-free solution</li>
        </ul>
      </div>
    </div>

    <div className="flex items-start gap-4">
      <div className="w-8 h-8 bg-red-100 rounded-full flex items-center justify-center flex-shrink-0">
        <span className="text-red-600 font-bold">√ó</span>
      </div>
      <div>
        <p className="font-semibold">Skip VS if you need:</p>
        <ul className="text-sm text-gray-600 mt-1 space-y-1">
          <li>‚Ä¢ Single correct answer (math, facts)</li>
          <li>‚Ä¢ Maximum speed (adds overhead)</li>
          <li>‚Ä¢ Deterministic output</li>
        </ul>
      </div>
    </div>
  </div>
</div>

## Implementation Tips

<div className="not-prose grid grid-cols-1 md:grid-cols-2 gap-4 mb-12">
  <div className="bg-blue-50 rounded-lg p-4">
    <h3 className="font-semibold mb-2">‚úÖ Do</h3>
    <ul className="text-sm space-y-1">
      <li>‚Ä¢ Use k=5 for optimal quality/diversity</li>
      <li>‚Ä¢ Ask for "probability" (not "likelihood")</li>
      <li>‚Ä¢ Specify JSON format for parsing</li>
      <li>‚Ä¢ Set œÑ threshold for diversity control</li>
    </ul>
  </div>
  <div className="bg-red-50 rounded-lg p-4">
    <h3 className="font-semibold mb-2">‚ùå Don't</h3>
    <ul className="text-sm space-y-1">
      <li>‚Ä¢ Use k>10 (quality degrades)</li>
      <li>‚Ä¢ Mix probability/confidence terms</li>
      <li>‚Ä¢ Forget to normalize probabilities</li>
      <li>‚Ä¢ Apply to factual/math tasks</li>
    </ul>
  </div>
</div>

## Frequently Asked Questions

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Does VS hurt accuracy or safety?</summary>
  <p className="mt-3 text-gray-600">
    No. The paper shows VS maintains factual accuracy (Appendix G.7) and safety (Appendix G.8).
    It only increases diversity for tasks with multiple valid answers.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">What is semantic diversity?</summary>
  <p className="mt-3 text-gray-600">
    Semantic diversity = 1 - mean(pairwise cosine similarity). It measures how different
    the meanings are across generated responses, not just surface-level word differences.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Why not just use temperature?</summary>
  <p className="mt-3 text-gray-600">
    Temperature and VS are orthogonal. Temperature affects sampling randomness from the same
    distribution, while VS changes the distribution itself. Combining them gives best results.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-12">
  <summary className="font-semibold cursor-pointer">Which models support VS?</summary>
  <p className="mt-3 text-gray-600">
    Any instruction-following LLM: GPT-4, Claude, Gemini, Llama, Qwen, and even reasoning
    models like o1 and DeepSeek R1. No special access or modifications needed.
  </p>
</details>

## Citation

<CodeBlock
  code={`@article{zhang2025verbalized,
  title={Verbalized Sampling: How to Mitigate Mode Collapse and Unlock LLM Diversity},
  author={Zhang, Jiayi and Yu, Simon and Chong, Derek and Sicilia, Anthony and Tomz, Michael R and Manning, Christopher D and Shi, Weiyan},
  journal={arXiv preprint arXiv:2025.xxxxx},
  year={2025}
}`}
  language="bibtex"
  showLineNumbers={false}
  client:load
/>
