---
title: "Breaking Mode Collapse: How Verbalized Sampling Restores LLM Creativity"
description: "Ask for a distribution, not a single answer. A training-free method to restore diversity in aligned LLMs."
slug: verbalized-sampling
pubDatetime: 2025-10-03T00:00:00Z
featured: true
draft: false
tags:
  - llm
  - diversity
  - prompting
  - verbalized-sampling
---

import VSPlayground from "@/components/interactives/VSPlayground";
import TypicalityBiasExplainer from "@/components/interactives/TypicalityBiasExplainer";
import TemperatureAblation from "@/components/interactives/TemperatureAblation";
import DiversityGainsVisual from "@/components/evidence/DiversityGainsVisual";
import PostTrainingVisual from "@/components/evidence/PostTrainingVisual";
import USStatesDemo from "@/components/evidence/USStatesDemo";
import ScalingTrendVisualization from "@/components/evidence/ScalingTrendVisualization";
import QuickStart from "@/components/sections/QuickStart";
import QualitativeExamples from "@/components/sections/QualitativeExamples";
import VSVariantsComparison from "@/components/sections/VSVariantsComparison";
import CodeBlock from "@/components/ui/CodeBlock";
import OpeningHook from "@/components/sections/OpeningHook";
import AhaMoment from "@/components/sections/AhaMoment";
import { Sidenote, Figure } from "@/components/academic";

<div className="not-prose flex justify-center gap-3 my-6">
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-green-100 text-green-800 font-semibold">
    ✨ Training-Free
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-blue-100 text-blue-800 font-semibold">
    🚀 Works with GPT, Claude, Gemini
  </span>
  <span className="inline-flex items-center px-4 py-2 rounded-full bg-purple-100 text-purple-800 font-semibold">
    📈 1.6-2.1× Diversity Gain
  </span>
</div>

## TL;DR

Human readers encounter mode‑collapsed outputs when asking for multiple ideas. Alignment amplifies typical completions; VS asks for a distribution to recover diversity.

- RLHF introduces **typicality bias** ($\varepsilon>0$) → sharpening and mode collapse ($\rho = 1 + \varepsilon/\beta > 1$) [@rafailov2024; @ouyang2022].
- VS prompts for a **probability distribution** over candidates rather than a single instance [@zhang2025vs].
- A threshold $\tau$ allows **diversity tuning** without retraining [@zhang2025vs, pp. 7–8].

<div className="not-prose mb-10">
  <OpeningHook client:visible />
</div>

{/* Quick Start moved to Recipes per IA alignment */}

## Why It Works

### 1. Hidden bias in preference data

Human annotators systematically prefer familiar/typical text<Sidenote number={1}>Classic effects include mere exposure and processing fluency [@zajonc1968; @reber2004; @alter2009]. Statistical analyses indicate $\varepsilon>0$ independent of correctness (e.g., paired‑comparison style tests) [@ouyang2022; @christiano2017].</Sidenote>:

$$r(x,y) = r_{\text{true}}(x,y) + \varepsilon\,\log p_{\text{base}}(y|x).$$

### 2. Sharpening → mode collapse

<a id="eq:sharpening" />
$$\pi^*(y|x) \propto \pi_{\text{ref}}(y|x)^{\rho},\quad \rho = 1 + \varepsilon/\beta > 1.$$

When utility is flat across many valid completions, sharpening concentrates mass on typical outputs<Sidenote number={2}>Derivation follows standard KL‑regularized preference learning [@rafailov2024] with typicality‑biased rewards; see [@zhang2025vs, Eq. 3, p. 4].</Sidenote>.

### 3. Distribution‑level recovery (VS)

VS asks for a distribution of candidates with probabilities, recovering pretraining diversity. On the US states task, VS aligns with the corpus distribution ($\mathrm{KL}\approx 0.12$) [@zhang2025vs, p. 3].

Sharpening is defined in [Eq. @eq:sharpening](#eq:sharpening).

<Figure id="us-states" caption="Distribution recovery on US states (VS vs Direct); lower KL indicates closer match to the pretraining distribution [@zhang2025vs, Figure 2].">
  <USStatesDemo client:visible />
</Figure>

VS recovers the pretraining distribution closely<Sidenote number={3}>This KL divergence is measured against the empirical pretraining distribution for US states [@zhang2025vs, Figure 2, p. 3].</Sidenote>.

<div className="not-prose mb-10">
  <AhaMoment client:visible />
</div>

## Interactive Explainer: Typicality Bias

<div className="not-prose mb-12">
  <TypicalityBiasExplainer client:visible />
</div>

## Try It: Diversity Playground

Adjust the probability threshold τ to see how it affects which outputs are included. Lower thresholds = more diversity, higher thresholds = more focused outputs.

This threshold‑tuning effect corresponds to the paper’s ablations [@zhang2025vs, Figure 3g–i]<Sidenote number={4}>As τ increases, fewer low‑probability candidates are included; diversity decreases but focus increases. See [@zhang2025vs, Figure 3g–i].</Sidenote>.

<div className="not-prose mb-12">
  <VSPlayground client:visible />
</div>

## Evidence

VS increases diversity by **1.6–2.1×** across poem/story/joke tasks [@zhang2025vs, Figure 3a–c], improves human preference by **+25.7%** [@zhang2025vs, Table 3], and recovers **66.8%** of base‑model diversity after alignment [@zhang2025vs, Figure 4].

See [Figure @fig:diversity-gains](#fig:diversity-gains) and [Figure @fig:post-training](#fig:post-training) for details.

<Figure id="diversity-gains" caption="Creative writing diversity improvements with VS (poem, story, joke); VS‑CoT achieves 1.6–2.1× gains [@zhang2025vs, Figure 3a–c].">
  <DiversityGainsVisual client:visible />
</Figure>

<Figure id="post-training" caption="Diversity retention across training stages; VS recovers to 66.8% of base diversity [@zhang2025vs, Figure 4].">
  <PostTrainingVisual client:visible />
</Figure>

## VS ≠ Temperature: Orthogonal Benefits

Temperature changes how you sample from a distribution; VS changes what distribution you request. They combine effectively [@zhang2025vs, Figure 5].

See [Figure @fig:temperature-ablation](#fig:temperature-ablation) for the combined diversity–quality Pareto frontier<Sidenote number={5}>VS shifts the underlying distribution, while temperature adjusts sampling from that distribution; their effects are complementary [@zhang2025vs, Figure 5].</Sidenote>.

<Figure id="temperature-ablation" caption="VS is orthogonal to temperature; combining the two improves the diversity–quality frontier [@zhang2025vs, Figure 5].">
  <TemperatureAblation client:visible />
</Figure>

## Larger Models Benefit More

Larger models show stronger gains with VS<Sidenote number={6}>Scaling analysis indicates ~1.5–2× larger diversity gains for higher‑capacity models [@zhang2025vs, Figure 3e–f, p. 7].</Sidenote>.

<Figure id="scaling-trend" caption="Larger models benefit ~1.5–2× more from VS [@zhang2025vs, Figure 3e–f].">
  <ScalingTrendVisualization client:visible />
</Figure>

## Dialogue Simulation

In dialogue simulation tasks, GPT‑4 with VS matches a fine‑tuned Llama‑3.1‑8B model, and DeepSeek‑R1 with VS surpasses it [@zhang2025vs, Figure 6a, p. 11]. This illustrates VS’s applicability beyond creative generation into behaviorally grounded distributions.

## VS Variants: When to Use Which

<div className="not-prose mb-12">
  <VSVariantsComparison client:visible />
</div>

Per Appendix H.3, “probability” performs best for VS‑Standard/CoT, while “confidence” is used in VS‑Multi [@zhang2025vs].

## Qualitative Examples

See the difference in actual outputs between direct prompting and VS:

<div className="not-prose mb-12">
  <QualitativeExamples client:visible />
</div>

## Is VS Right for You?

Use VS when you need creative diversity (stories, jokes, ideas), realistic distributions (simulations, surveys), or variety in synthetic data — and when a training‑free method is preferred. Skip VS for tasks requiring a single correct answer, strict determinism, or maximal speed.

## Prompt Recipes

<div className="not-prose mb-6">
  <QuickStart client:load />
  {/* Quick Start embedded here for copy‑ready flow */}
  </div>

### VS‑Standard (JSON)

<CodeBlock
  code={`Generate k={5} {TASK} with their probabilities.\nReturn JSON: {\"candidates\":[{\"text\":\"...\",\"prob\":0.28}, ...]}\nOnly include candidates with probability ≥ {τ}. Ensure probabilities sum to 1.`}
  language="text"
  client:idle
/>

### VS‑CoT

<CodeBlock
  code={`Think step-by-step to enumerate distinct styles/approaches.\nThen generate k={5} {TASK} with probabilities in JSON (probabilities sum to 1).\nOnly include items with probability ≥ {τ}.`}
  language="text"
  client:idle
/>

### VS‑Multi (confidence)

<CodeBlock
  code={`Generate k={5} {TASK} candidates.\nFor each, return text and confidence ∈ [0,1]. Only include items with confidence ≥ {τ_conf}.`}
  language="text"
  client:idle
/>

## Implementation Tips

Do:

- Use `k=5` for quality/diversity; larger `k` often degrades quality<Sidenote number={7}>Empirically, diminishing returns beyond k=5 with quality degradation for k>10 [@zhang2025vs, Appendix H.1].</Sidenote>.
- Ask for “probability” (not “likelihood”) in VS‑Standard/CoT.
- Specify JSON and ensure probabilities sum to 1.
- Use a $\tau$ threshold for diversity control.

Don’t:

- Use `k>10` unless necessary.
- Mix “probability” and “confidence” terms.
- Forget normalization.
- Apply VS to strictly factual/math tasks.

## Frequently Asked Questions

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Does VS hurt accuracy or safety?</summary>
  <p className="mt-3 text-gray-600">
    No. The paper shows VS maintains factual accuracy (Appendix G.7) and safety (Appendix G.8) [@zhang2025vs].
    It only increases diversity for tasks with multiple valid answers.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">What is semantic diversity?</summary>
  <p className="mt-3 text-gray-600">
    Semantic diversity = $1 - \mathrm{mean}(\mathrm{cosine\_similarity})$. It measures how different
    the meanings are across generated responses, not just surface-level word differences.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-3">
  <summary className="font-semibold cursor-pointer">Why not just use temperature?</summary>
  <p className="mt-3 text-gray-600">
    Temperature and VS are orthogonal. Temperature affects sampling randomness from the same
    distribution, while VS changes the distribution itself [@zhang2025vs, Figure 5]. Combining them gives best results.
  </p>
</details>

<details className="bg-white rounded-lg p-4 border border-gray-200 mb-12">
  <summary className="font-semibold cursor-pointer">Which models support VS?</summary>
  <p className="mt-3 text-gray-600">
    Any instruction-following LLM: GPT-4, Claude, Gemini, Llama, Qwen, and even reasoning
    models like o1 and DeepSeek R1. No special access or modifications needed.
  </p>
</details>

## References

<section id="references" />
